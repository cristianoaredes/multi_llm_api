# ğŸš€ MultiLLM API

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Status: WIP](https://img.shields.io/badge/Status-WIP-yellow.svg)](https://github.com/cristianoaredes/multi-llm-api)
[![Dart Version](https://img.shields.io/badge/Dart-3.0%2B-blue)](https://dart.dev)
[![Docker](https://img.shields.io/badge/Docker-Supported-blue?logo=docker)](https://www.docker.com/)

Uma API backend robusta e escalÃ¡vel construÃ­da com Dart e o framework Shelf, projetada para servir como um gateway unificado para mÃºltiplos modelos de linguagem (LLMs). Este projeto integra nativamente APIs como Google Gemini e OpenRouter, permitindo acesso padronizado a diversos modelos como GPT, Claude, Llama, etc.

![MultiLLM API Banner](assets/images/banner.png)

> **âš ï¸ AVISO: Este projeto estÃ¡ em desenvolvimento ativo (WIP)**  
> Funcionalidades podem mudar e a API ainda nÃ£o Ã© considerada estÃ¡vel para uso em produÃ§Ã£o.

## âœ¨ Recursos

- **Arquitetura feature-first** para cÃ³digo modular e organizado
- **Gateway unificado para mÃºltiplos LLMs**:
  - Google Gemini API
  - OpenRouter (acesso a OpenAI GPT, Anthropic Claude, Meta Llama, etc.)
  - Interface padronizada para mÃºltiplos provedores
- **Streaming de respostas** em tempo real
- **Sistema de fallback** entre provedores
- **AutenticaÃ§Ã£o completa com JWT**
- **Sistema de validaÃ§Ã£o e sanitizaÃ§Ã£o** de entrada para proteger contra injeÃ§Ãµes
- **PostgreSQL** para armazenamento de dados
- **Cache** para otimizaÃ§Ã£o de performance
- **DocumentaÃ§Ã£o OpenAPI/Swagger** integrada
- **ConfiguraÃ§Ã£o por ambiente** (desenvolvimento, produÃ§Ã£o, teste)
- **ContÃªinerizaÃ§Ã£o** com Docker e Docker Compose
- **Testes abrangentes** unitÃ¡rios e de integraÃ§Ã£o

## ğŸ—ï¸ Arquitetura

A aplicaÃ§Ã£o segue o padrÃ£o feature-first, promovendo separaÃ§Ã£o de preocupaÃ§Ãµes e modularidade:

```
multi-llm-api/
â”œâ”€â”€ bin/              # Ponto de entrada da aplicaÃ§Ã£o
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ core/         # Componentes centrais (config, DI, middleware, etc.)
â”‚   â”‚   â”œâ”€â”€ config/   # ConfiguraÃ§Ãµes da aplicaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ di/       # InjeÃ§Ã£o de dependÃªncia
â”‚   â”‚   â”œâ”€â”€ error/    # Tratamento de erros
â”‚   â”‚   â”œâ”€â”€ logging/  # ConfiguraÃ§Ã£o de logs
â”‚   â”‚   â”œâ”€â”€ middleware/ # Middlewares da aplicaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ server/   # ConfiguraÃ§Ã£o do servidor
â”‚   â”‚   â””â”€â”€ utils/    # UtilitÃ¡rios
â”‚   â”œâ”€â”€ features/     # MÃ³dulos de funcionalidades
â”‚   â”‚   â”œâ”€â”€ auth/     # AutenticaÃ§Ã£o e autorizaÃ§Ã£o
â”‚   â”‚   â”‚   â”œâ”€â”€ data/     # Camada de dados
â”‚   â”‚   â”‚   â”œâ”€â”€ domain/   # Camada de domÃ­nio
â”‚   â”‚   â”‚   â””â”€â”€ presentation/ # Camada de apresentaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ generative/ # IA Generativa
â”‚   â”‚       â”œâ”€â”€ domain/   # Camada de domÃ­nio
â”‚   â”‚       â””â”€â”€ presentation/ # Camada de apresentaÃ§Ã£o
â”‚   â””â”€â”€ generated_api/ # CÃ³digo gerado
â”œâ”€â”€ openapi/          # DocumentaÃ§Ã£o da API
â”œâ”€â”€ test/             # Testes
â””â”€â”€ ...               # Outros arquivos de configuraÃ§Ã£o
```

## ğŸš€ InÃ­cio RÃ¡pido

### Usando Docker (Recomendado)

1. **Clone o repositÃ³rio**

```bash
git clone https://github.com/cristianoaredes/multi-llm-api.git
cd multi-llm-api
```

2. **Configure o ambiente**

```bash
cp .env.example .env.development
# Edite .env.development com suas chaves de API e configuraÃ§Ãµes
```

3. **Execute com Docker Compose**

```bash
docker-compose up -d
```

4. **Acesse os serviÃ§os**

- **API**: http://localhost:8081
- **DocumentaÃ§Ã£o (Swagger)**: http://localhost:8083
- **Gerenciador de DB (Adminer)**: http://localhost:8082

### Localmente

1. **PrÃ©-requisitos**: Dart SDK 3.0+, PostgreSQL (opcional), Redis (opcional)

2. **Instale dependÃªncias**

```bash
dart pub get
```

3. **Configure o ambiente**

```bash
cp .env.example .env
# Edite .env com suas configuraÃ§Ãµes
```

4. **Execute a aplicaÃ§Ã£o**

```bash
dart run bin/server.dart
```

## ğŸ“‹ Endpoints da API

### AutenticaÃ§Ã£o

- `POST /api/v1/auth/register` - Registre um novo usuÃ¡rio
- `POST /api/v1/auth/login` - Autentique e receba um token JWT
- `POST /api/v1/auth/refresh` - Atualize um token JWT
- `POST /api/v1/auth/logout` - Invalide um token

### IA Generativa

- `GET /api/v1/generate/models` - Liste os modelos disponÃ­veis
- `POST /api/v1/generate/text` - Gere texto a partir de um prompt
- `POST /api/v1/generate/text/stream` - Stream de texto gerado em tempo real
- `POST /api/v1/generate/chat` - Continue uma conversa com IA
- `POST /api/v1/generate/chat/stream` - Stream de respostas de chat em tempo real
- `GET /api/v1/generate/info` - InformaÃ§Ãµes sobre o modelo atual
- `POST /api/v1/generate/cache/clear` - Limpe o cache de respostas

## ğŸ”§ ConfiguraÃ§Ã£o

A aplicaÃ§Ã£o usa arquivos `.env` para diferentes ambientes. VariÃ¡veis importantes incluem:

```env
# Servidor
SERVER_PORT=8080
LOG_LEVEL=INFO
ENVIRONMENT=development

# JWT
JWT_SECRET="sua_chave_secreta"
JWT_EXPIRATION_HOURS=24

# AI Provider (gemini ou openrouter)
AI_PROVIDER=gemini

# Gemini API
GEMINI_API_KEY="sua_chave_api_gemini"
GEMINI_MODEL="gemini-1.5-flash-latest"
GEMINI_MAX_TOKENS=2048
GEMINI_TEMPERATURE=0.7
GEMINI_SAFETY_HARASSMENT=BLOCK_MEDIUM_AND_ABOVE
GEMINI_SAFETY_HATE_SPEECH=BLOCK_MEDIUM_AND_ABOVE
GEMINI_SAFETY_SEXUALLY_EXPLICIT=BLOCK_MEDIUM_AND_ABOVE
GEMINI_SAFETY_DANGEROUS=BLOCK_MEDIUM_AND_ABOVE
GEMINI_ENABLE_STREAMING=true

# OpenRouter API
OPENROUTER_API_KEY="sua_chave_api_openrouter"
OPENROUTER_BASE_URL="https://openrouter.ai/api/v1"
OPENROUTER_MODEL="openai/gpt-3.5-turbo"
OPENROUTER_MAX_TOKENS=2048
OPENROUTER_TEMPERATURE=0.7
OPENROUTER_ENABLE_STREAMING=true

# Database
DB_HOST=localhost
DB_PORT=5432
DB_NAME=multi_llm_api
DB_USERNAME=postgres
DB_PASSWORD=postgres
```

## ğŸ§ª Testes

Execute os testes com:

```bash
dart test
```

Para ver a cobertura de testes:

```bash
dart run scripts/run_tests_with_coverage.sh
```

## ğŸ“š Exemplos de Uso

### Gerando Texto

```bash
curl -X POST http://localhost:8081/api/v1/generate/text \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer seu_token_jwt" \
  -d '{"prompt": "Explique como fazer uma API em Dart", "model_id": "gemini-1.5-flash"}'
```

### Streaming de Chat

```javascript
// JavaScript (front-end)
const eventSource = new EventSource('http://localhost:8081/api/v1/generate/chat/stream');
eventSource.onmessage = (event) => {
  const data = JSON.parse(event.data);
  if (data.chunk) {
    // Processar cada chunk de texto recebido
    console.log(data.chunk);
  }
};
```

## ğŸ› ï¸ Tecnologias

- **Dart** e framework **Shelf**
- **PostgreSQL** para persistÃªncia
- **JWT** para autenticaÃ§Ã£o
- **Google Gemini API** para IA generativa
- **OpenRouter** para acesso a mÃºltiplos LLMs
- **OpenAPI/Swagger** para documentaÃ§Ã£o
- **Docker** para containerizaÃ§Ã£o

## ğŸ”„ Roteiro de Desenvolvimento

- [x] IntegraÃ§Ã£o com Google Gemini
- [x] IntegraÃ§Ã£o com OpenRouter
- [x] AutenticaÃ§Ã£o JWT
- [x] Middleware de sanitizaÃ§Ã£o
- [x] Streaming de respostas
- [x] ConfiguraÃ§Ãµes de seguranÃ§a
- [x] Completar a renomeaÃ§Ã£o do pacote de 'api_dart' para 'multi_llm_api' em todos os arquivos
- [ ] Implementar sistema de fallback entre modelos
- [ ] Suporte a prompts multimodais (imagens, Ã¡udio)
- [ ] Implementar cache distribuÃ­do
- [ ] Melhorar a documentaÃ§Ã£o da API

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor, siga estes passos:

1. Verifique os issues abertos ou abra um novo descrevendo sua contribuiÃ§Ã£o
2. FaÃ§a um fork do repositÃ³rio
3. Crie uma nova branch (`git checkout -b feature/nova-funcionalidade`)
4. FaÃ§a commit das suas mudanÃ§as (`git commit -m 'feat: adiciona nova funcionalidade'`)
5. Envie para a branch (`git push origin feature/nova-funcionalidade`)
6. Abra um Pull Request

Este projeto segue o fluxo de trabalho GitFlow e usa o padrÃ£o de commits convencionais.

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ™ Agradecimentos

- A comunidade Dart por fornecer excelentes ferramentas
- Todos os contribuidores que ajudaram a melhorar este projeto

## ğŸ” Palavras-chave

`dart` `api` `llm` `generative-ai` `chatgpt` `gemini` `claude` `jwt` `rest-api` `streaming` `docker` `postgresql` `shelf` `openapi` `swagger` `security` `sanitization` `middleware` `clean-architecture` `feature-first` `dependency-injection`

## ğŸ“Š MÃ©tricas do Projeto

![GitHub stars](https://img.shields.io/github/stars/cristianoaredes/multi-llm-api?style=social)
![GitHub forks](https://img.shields.io/github/forks/cristianoaredes/multi-llm-api?style=social)
![GitHub issues](https://img.shields.io/github/issues/cristianoaredes/multi-llm-api?style=social)

## ğŸ¤ Mantenedores

| [**Cristiano Aredes**](https://github.com/cristianoaredes) |
| ---------------------------------------------------------- |
| Mobile Architect & AI Engineer - [aredes.me](https://aredes.me) |

## ğŸ“« Contato

Para sugestÃµes, dÃºvidas ou contribuiÃ§Ãµes:

* ğŸŒ Site: [aredes.me](https://aredes.me)
* ğŸ“§ Email: cristiano@aredes.me
* ğŸ’¼ LinkedIn: [Cristiano Aredes](https://www.linkedin.com/in/cristianoaredes/)

## â­ Mostre seu apoio

Se este projeto te ajudou de alguma forma, considere:

* â­ Dar uma estrela no GitHub
* ğŸ› Reportar bugs ou sugerir melhorias em Issues
* ğŸ”€ Fazer um fork e contribuir com o projeto
* ğŸ“¢ Compartilhar com outros desenvolvedores

## ğŸ“ CitaÃ§Ã£o

Se vocÃª usar este projeto como referÃªncia em artigos ou estudos, por favor cite:

```bibtex
@software{multi_llm_api,
  author = {Cristiano Aredes},
  title = {MultiLLM API - Gateway para MÃºltiplos Modelos de Linguagem},
  year = {2024},
  publisher = {GitHub},
  url = {https://github.com/cristianoaredes/multi-llm-api}
}
```



 Feito com â¤ï¸ por [Cristiano Aredes](https://aredes.me) 


â­ **Gostou deste projeto? DÃª uma estrela!** â­# multi_llm_api

